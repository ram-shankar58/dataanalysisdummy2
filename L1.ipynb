import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder

# Load the training data
train_data = pd.read_csv("/kaggle/input/inputfiles/train.csv")

# Separate features and target variable for training data
X_train = train_data.drop(columns=["House"])  # Keep 'ID' and other columns except 'House'
y_train = train_data["House"]

# Define numerical and categorical columns
numerical_cols = ['Intelligence', 'Loyalty', 'Affinity to Dark Arts', 'Height', 'Kindness']
categorical_cols = ['Blood Status', 'Gender', 'What are you curious about?', 'Preferred Goblet Potion',
                    'If you were a principal, how would you choose your students?', 'Species', 'Preferred Element',
                    'Magic Transportation Model']

# Preprocessing for numerical data: fill missing values with the mean and scale
numerical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="mean")),
    ("scaler", StandardScaler())
])

# Preprocessing for categorical data: fill missing values with the most frequent value and one-hot encoding
categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(drop="first"))
])

# Bundle preprocessing for numerical and categorical data
preprocessor = ColumnTransformer(
    transformers=[
        ("num", numerical_transformer, numerical_cols),
        ("cat", categorical_transformer, categorical_cols)
    ])

# Define the model
model = RandomForestClassifier(n_estimators=100, random_state=0)

# Bundle preprocessing and modeling code in a pipeline
clf = Pipeline(steps=[('preprocessor', preprocessor),
                      ('model', model)])

# Preprocessing of training data, fit model 
clf.fit(X_train, y_train)

# Load the test data
test_data = pd.read_csv("/kaggle/input/inputfiles/Kaggle_test.csv")

# Retain 'ID' in the test dataset
X_test = test_data.copy()  # Make a copy of the test data

# Preprocessing of test data, get predictions
X_test_preprocessed = preprocessor.transform(X_test)
y_test_pred = clf.predict(X_test_preprocessed)

# Add the predictions to the test data
test_data["Predicted_House"] = y_test_pred

# Save the test data with predictions to a CSV file
test_data.to_csv("predicted_test_data.csv", index=False)

# You can now use the "predicted_test_data.csv" file to submit your predictions.
